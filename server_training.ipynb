{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split        \n",
    "from torchvision import transforms\n",
    "import os\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import torch_geometric.nn as geom_nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "2 -1 9169\n",
      "7 -1 8571\n",
      "1 -1 7419\n",
      "3 -1 7330\n",
      "6 -1 6939\n",
      "4 -1 8827\n",
      "5 -1 7510\n",
      "torch.Size([55765, 3, 360, 360])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import Data_Loader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print (device)\n",
    "# FER Dataset\n",
    "#data_folder_path = 'FER_2013/train'\n",
    "#label_mapping = {'fear': 1, 'angry': 2, 'happy': 3, 'sad': 4, 'surprise': 5, 'neutral': 6,'disgust': 7}\n",
    "\n",
    "# CK+ Dataset\n",
    "#data_folder_path = 'CK+/CK+'\n",
    "#label_mapping = {'fear': 1, 'anger': 2, 'happy': 3, 'sadness': 4, 'surprise': 5, 'contempt': 6, 'disgust': 7}\n",
    "#data_folder_path = '/content/drive/MyDrive/CK/FER/train'\n",
    "\n",
    "#FERG\n",
    "data_folder_path = 'FERG/FERG'\n",
    "label_mapping = {'fear': 1, 'anger': 2, 'joy': 3, 'sadness': 4, 'surprise': 5, 'neutral': 6,'disgust': 7}\n",
    "#FERG\n",
    "#data_folder_path = 'JAFFE/jaffedbase'\n",
    "#label_mapping = {'fear': 1, 'angry': 2, 'happy': 3, 'sad': 4, 'surprise': 5, 'neutral': 6,'disgust': 7}\n",
    "\n",
    "test_size  = 0.2\n",
    "val_size   = 0.1\n",
    "batch_size =  18\n",
    "images_per_class= -1\n",
    "\n",
    "train_loader,test_loader,val_loader = Data_Loader.Read_Data(data_folder_path,label_mapping,device, images_per_class, test_size, val_size, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified model ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import torch_geometric.nn as geom_nn\n",
    "\n",
    "class GCF(nn.Module):\n",
    "    def __init__(self, num_classes, device, base_model='vgg16', mode='cnn+gcn'):\n",
    "        super(GCF, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.device = device\n",
    "        self.base_model = base_model.lower()\n",
    "\n",
    "        # Load the selected pretrained model and define feature size\n",
    "        cnn_output_size = 0\n",
    "\n",
    "        if self.base_model == 'vgg16':\n",
    "            self.model = models.vgg16(pretrained=True)\n",
    "            num_ftrs = self.model.classifier[-1].in_features\n",
    "            self.model.classifier = nn.Sequential(*list(self.model.classifier.children())[:-1], nn.Flatten())\n",
    "            cnn_output_size = 4096\n",
    "\n",
    "        elif self.base_model == 'vgg19':\n",
    "            self.model = models.vgg19(pretrained=True)\n",
    "            num_ftrs = self.model.classifier[-1].in_features\n",
    "            self.model.classifier = nn.Sequential(*list(self.model.classifier.children())[:-1], nn.Flatten())\n",
    "            cnn_output_size = 4096\n",
    "\n",
    "        elif self.base_model == 'resnet18':\n",
    "            self.model = models.resnet18(pretrained=True)\n",
    "            num_ftrs = self.model.fc.in_features\n",
    "            self.model.fc = nn.Flatten()\n",
    "            cnn_output_size = 512\n",
    "\n",
    "        elif self.base_model == 'resnet34':\n",
    "            self.model = models.resnet34(pretrained=True)\n",
    "            num_ftrs = self.model.fc.in_features\n",
    "            self.model.fc = nn.Flatten()\n",
    "            cnn_output_size = 512\n",
    "\n",
    "        elif self.base_model == 'resnet50':\n",
    "            self.model = models.resnet50(pretrained=True)\n",
    "            num_ftrs = self.model.fc.in_features\n",
    "            self.model.fc = nn.Flatten()\n",
    "            cnn_output_size = 2048\n",
    "\n",
    "        elif self.base_model == 'densenet121':\n",
    "            self.model = models.densenet121(pretrained=True)\n",
    "            num_ftrs = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Sequential(nn.Flatten())\n",
    "            cnn_output_size = 1024\n",
    "\n",
    "        elif self.base_model == 'densenet169':\n",
    "            self.model = models.densenet169(pretrained=True)\n",
    "            num_ftrs = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Sequential(nn.Flatten())\n",
    "            cnn_output_size = 1664\n",
    "\n",
    "        elif self.base_model == 'densenet201':\n",
    "            self.model = models.densenet201(pretrained=True)\n",
    "            num_ftrs = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Sequential(nn.Flatten())\n",
    "            cnn_output_size = 1920\n",
    "\n",
    "        elif self.base_model == 'efficientnet_b0':\n",
    "            self.model = models.efficientnet_b0(pretrained=True)\n",
    "            num_ftrs = self.model.classifier[-1].in_features\n",
    "            self.model.classifier = nn.Flatten()\n",
    "            cnn_output_size = 1280\n",
    "\n",
    "        elif self.base_model == 'inception_v3':\n",
    "            self.model = models.inception_v3(pretrained=True, aux_logits=True)\n",
    "            num_ftrs = self.model.fc.in_features\n",
    "            self.model.fc = nn.Flatten()\n",
    "            cnn_output_size = 2048\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported base model: {self.base_model}\")\n",
    "\n",
    "        # Define output sizes and fully connected layers\n",
    "        gcn_output_size = 128\n",
    "        if self.mode == \"cnn\" or self.mode == \"cnn+gcn\":\n",
    "            self.fc_cnn = nn.Linear(num_ftrs, cnn_output_size)\n",
    "        if self.mode == \"gcn\" or self.mode == \"cnn+gcn\":\n",
    "            self.fc_gcn = nn.Linear(256, gcn_output_size)\n",
    "\n",
    "        combined_output_size = cnn_output_size + gcn_output_size if mode == \"cnn+gcn\" else max(cnn_output_size, gcn_output_size)\n",
    "        self.fc = nn.Linear(combined_output_size, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.gnn = self._build_gnn_layer(cnn_output_size)\n",
    "\n",
    "    def _build_gnn_layer(self, cnn_output_size):\n",
    "        return GNNLayer(in_channels=cnn_output_size, hidden_channels=256, out_channels=256, device=self.device)\n",
    "\n",
    "    def forward(self, images):\n",
    "        images = images.to(self.device)\n",
    "        cnn_features = self.model(images)\n",
    "\n",
    "        if self.mode == \"cnn\" or self.mode == \"cnn+gcn\":\n",
    "            cnn_features = cnn_features.view(cnn_features.size(0), -1)\n",
    "            cnn_features = self.fc_cnn(cnn_features)\n",
    "\n",
    "        if self.mode == \"gcn\" or self.mode == \"cnn+gcn\":\n",
    "            gcn_features = self.gnn(cnn_features)\n",
    "            gcn_features = gcn_features.view(gcn_features.size(0), -1)\n",
    "            gcn_features = self.fc_gcn(gcn_features)\n",
    "\n",
    "        if self.mode == \"cnn+gcn\":\n",
    "            features = torch.cat((cnn_features, gcn_features), dim=1)\n",
    "        elif self.mode == \"cnn\":\n",
    "            features = cnn_features\n",
    "        else:\n",
    "            features = gcn_features\n",
    "\n",
    "        out = self.fc(features)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc3(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class GNNLayer(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, device):\n",
    "        super(GNNLayer, self).__init__()\n",
    "        self.conv1 = geom_nn.GraphConv(in_channels, hidden_channels)\n",
    "        self.device = device\n",
    "        \n",
    "        \n",
    "        #VERSION 2\n",
    "        #self.edge_index = torch.tensor(\n",
    "        #    [[0, 1, 0, 3, 0, 4, 1, 2, 1, 4, 3, 4, 3, 6, 4, 5, 4, 7, 6, 7, 7, 8, 2, 4, 4, 6, 5, 4, 4, 8],\n",
    "        #     [0, 1, 0, 3, 0, 4, 1, 2, 1, 4, 3, 4, 3, 6, 4, 5, 4, 7, 6, 7, 7, 8, 2, 4, 4, 6, 5, 4, 4, 8]],\n",
    "        #    dtype=torch.long).to(self.device)\n",
    "        \n",
    "\n",
    "        # VERSION 3\n",
    "        self.edge_index = torch.tensor(\n",
    "            [[1, 0, 3, 0, 4, 0, 2, 1, 4, 1, 4, 3, 6, 3, 5, 4, 7, 4, 7, 6, 8, 7, 4, 2, 6, 4, 4, 5, 8, 4],\n",
    "             [1, 0, 3, 0, 4, 0, 2, 1, 4, 1, 4, 3, 6, 3, 5, 4, 7, 4, 7, 6, 8, 7, 4, 2, 6, 4, 4, 5, 8, 4]],\n",
    "            dtype=torch.long).to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.conv1(x, self.edge_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 GPU(s) available.\n",
      "GPU 0: NVIDIA GeForce RTX 4060 Ti\n",
      "GPU 1: NVIDIA GeForce RTX 4060 Ti\n",
      "Using GPU 1: NVIDIA GeForce RTX 4060 Ti\n"
     ]
    }
   ],
   "source": [
    "from Training import train\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def get_available_device():\n",
    "    if torch.cuda.is_available():\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        print(f\"Found {num_gpus} GPU(s) available.\")\n",
    "        for i in range(num_gpus):\n",
    "            print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        gpu_choice = 1\n",
    "        device = torch.device(f\"cuda:{gpu_choice}\")\n",
    "        print(f\"Using GPU {gpu_choice}: {torch.cuda.get_device_name(gpu_choice)}\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"CUDA is not available. Using CPU.\")\n",
    "    return device\n",
    "\n",
    "device = get_available_device()\n",
    "#device = torch.device(\"cpu\")\n",
    "def gcf_train(mode,base):\n",
    "  num_classes = 8\n",
    "  GCF_model = GCF(num_classes,device,base_model=base, mode=mode).to(device)\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.Adam(GCF_model.parameters(), lr=0.00005,weight_decay=1e-4)\n",
    "  num_epochs = 20\n",
    "  train(GCF_model,device,train_loader,val_loader,num_epochs,criterion,optimizer)\n",
    "  output_path = \"D:/GCF\"\n",
    "  model_filename = f\"FER+{mode}\"\n",
    "  full_output_path = os.path.join(output_path, model_filename)\n",
    "\n",
    "  torch.save(GCF_model.state_dict(), f\"Vgg16-Raf-{model_filename}.h5\")\n",
    "  return GCF_model\n",
    "\n",
    "\n",
    "def gcf_test(GCF_model):\n",
    "    GCF_model.eval()\n",
    "    criterion=nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = GCF_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "\n",
    "\n",
    "            total_predictions += targets.size(0)\n",
    "\n",
    "\n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "\n",
    "    print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------\n",
      "Processing Model: VGG16\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.04, Train Acc: 98.65%, Val Loss: 0.00, Val Acc: 99.98%\n",
      "Epoch 2/20, Train Loss: 0.01, Train Acc: 99.81%, Val Loss: 0.00, Val Acc: 100.00%\n",
      "Epoch 3/20, Train Loss: 0.01, Train Acc: 99.80%, Val Loss: 0.01, Val Acc: 99.75%\n",
      "Epoch 4/20, Train Loss: 0.00, Train Acc: 99.93%, Val Loss: 0.02, Val Acc: 99.69%\n",
      "Epoch 5/20, Train Loss: 0.01, Train Acc: 99.85%, Val Loss: 0.00, Val Acc: 100.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m40\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Initialize, train and test the model\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m GCF_model \u001b[38;5;241m=\u001b[39m gcf_train(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn+gcn\u001b[39m\u001b[38;5;124m\"\u001b[39m, base_model)\n\u001b[0;32m     20\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m gcf_test(GCF_model)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Add results to the list\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 30\u001b[0m, in \u001b[0;36mgcf_train\u001b[1;34m(mode, base)\u001b[0m\n\u001b[0;32m     28\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(GCF_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00005\u001b[39m,weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[0;32m     29\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m---> 30\u001b[0m train(GCF_model,device,train_loader,val_loader,num_epochs,criterion,optimizer)\n\u001b[0;32m     31\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/GCF\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     32\u001b[0m model_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFER+\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32md:\\GCF\\Training.py:28\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(GCF_model, device, train_loader, val_loader, num_epochs, criterion, optimizer)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Calculate training accuracy and loss\u001b[39;00m\n\u001b[0;32m     27\u001b[0m _, predicted_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(emotion_output, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m total_correct_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (predicted_train \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     29\u001b[0m total_samples_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     30\u001b[0m total_loss_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "models_list = [\n",
    "    'vgg16', 'vgg19', 'resnet18', 'resnet34', 'resnet50',\n",
    "    'densenet121', 'densenet169', 'densenet201',\n",
    "    'efficientnet_b0'\n",
    "]\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Loop through each model type, train and test\n",
    "for base_model in models_list:\n",
    "    print(\"\\n\" + \"-\"*40)\n",
    "    print(f\"Processing Model: {base_model.upper()}\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    # Initialize, train and test the model\n",
    "    GCF_model = gcf_train(\"cnn+gcn\", base_model)\n",
    "    accuracy = gcf_test(GCF_model)\n",
    "    \n",
    "    # Add results to the list\n",
    "    results.append([base_model, \"cnn+gcn\", accuracy])\n",
    "\n",
    "# Create a DataFrame from the results and display as a table\n",
    "results_df = pd.DataFrame(results, columns=[\"Base Model\", \"Mode\", \"Accuracy (%)\"])\n",
    "\n",
    "# Save results to Excel file\n",
    "results_df.to_excel(\"model_results.xlsx\", index=False)\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"\\nResults have been saved to 'model_results.xlsx'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
